<!DOCTYPE HTML>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script src="https://cdn.tailwindcss.com"></script>
<title>Analisa tidur Ver. 0.0.2</title>
<link href="./Video Capture Example_files/js_example_style.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"> </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/1.0.2/Chart.min.js"></script>
<script src="https://cdn.socket.io/socket.io-2.2.0.js" ></script>


<style>
    .center {
        margin: auto;
        width: 60%;
        padding: 10px;
    }
    .loader {
        border: 16px solid #f3f3f3; /* Light grey */
        border-top: 16px solid #3498db; /* Blue */
        border-radius: 50%;
        width: 120px;
        height: 120px;
        animation: spin 2s linear infinite;
    }

    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    .is-hide{
        display: none;
    }
    #myChart {
        width: 1900px !important;
        height: 400px !important;
    }
</style>
</head>

<body>
    <div id="loader" class="is-hide mt-[25%] ml-[50%]" >
        <div class="loader"></div>
        <div>Loading Model</div>
    </div>
    <div id="mainContent" class="is-hide">
        <div class="ml-4 mt-4 mb-4 mr-4 flex">
            <div class="mr-4">
                <video id="videoInput" style="display:none" width="320" height="240"></video>
                <canvas id="canvasOutput" width="320" height="240"></canvas>
            </div>
            <div>
                <div class="control">
                    <button class="bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded-full" id="startAndStop">Start</button>
                </div>
                <!-- </div> -->
                <div id="output" class="caption"></div>
                <div id="analizing" class="caption"></div>
            </div>
        </div>
        <div>
            <canvas id="myChart" width="1920" height="400" class="mr-2 ml-2"></canvas>
        </div>
        </div>

<!-- <script async src="https://grafias-dev.s3.eu-central-1.amazonaws.com/js/opencv.js" type="text/javascript"></script> -->
<script src="./Video Capture Example_files/adapter-5.0.4.js" type="text/javascript"></script>
<script src="./Video Capture Example_files/utils.js" type="text/javascript"></script>


<script type="text/javascript">
        let classOutput = document.getElementById('output')
        let analizingOutput = document.getElementById('analizing')
    // $(document).ready(function() {
        var ctx = document.getElementById("myChart").getContext("2d");
        ctx.canvas.parentNode.style.height = '400px';
        ctx.canvas.parentNode.style.width = '800px';
        const defaultData = Array.from(Array(128).keys())

        var chartData = {
            labels: defaultData,
            datasets: [{
                label: "My First dataset",
                fillColor: "transparent",
                strokeColor: "blue",
                pointColor: "transparent",
                pointStrokeColor: "transparent",
                pointHighlightFill: "transparent",
                pointHighlightStroke: "transparent",
                data: [4200.769,4195.385,4191.795,4194.615,4192.436,4194.231,4197.051,4195.385,4194.487,4194.744,4195.897,4195.385,4193.718,4194.872,4198.846,4195.897,4196.026,4204.359,4202.692,4194.359,4193.846,4197.564,4197.821,4198.205,4196.41,4193.974,4197.949,4196.41,4192.436,4192.821,4192.436,4192.949,4193.846,4191.026,4195.513,4202.692,4197.564,4197.051,4201.41,4200.128,4201.026,4200.256,4198.077,4200.385,4200.641,4195.256,4195.641,4202.308,4202.564,4198.974,4200.128,4201.282,4199.744,4198.205,4199.231,4202.308,4200.769,4198.333,4200.385,4201.41,4200.128,4200,4200.385,4200.897,4201.026,4200,4200.385,4202.949,4202.949,4202.179,4203.333,4202.179,4201.282,4202.436,4201.154,4199.872,4201.282,4202.564,4202.821,4200.769,4198.718,4200.513,4203.205,4202.179,4199.487,4199.359,4201.282,4202.051,4200,4199.359,4200.769,4201.282,4199.872,4198.846,4200.641,4201.538,4198.974,4197.436,4199.487,4200,4198.333,4198.846,4201.795,4201.41 ,4199.615,4200.256,4200.256,4201.026,4201.923,4200.897,4199.744,4200.513,4200.385,4200,4200.897,4200.513,4200.385,4201.154,4201.026,4200.385,4201.154,4200.641,4197.564,4198.718,4201.795,4201.154,4201.154,4202.692]
            }]
        };
        var options = {
            animation: false,
            tooltips: {enabled: false},
            events: [],
            hover: {mode: null},
            //Boolean - If we want to override with a hard coded scale
            scaleOverride: false,
            //** Required if scaleOverride is true **
            //Number - The number of steps in a hard coded scale
            scaleSteps: 10,
            //Number - The value jump in the hard coded scale
            scaleStepWidth: 10,
            //Number - The scale starting value
            scaleStartValue: 0,
            responsive: false,
            scales: {
                yAxes: [{
                    display: true,
                    ticks: {
                        suggestedMin: 0,    // minimum will be 0, unless there is a lower value.
                        suggestedMax: 1,    // minimum will be 0, unless there is a lower value.
                        // OR //
                        beginAtZero: true   // minimum value will be 0.
                    }
                }]
            }
        };

        var myLineChart = new Chart(ctx).Line(chartData, options);
        let counter = chartData.datasets[0].data.length;
        
        // setInterval(function() {
        
        // }, 300);

        function setLabels(labels) {
            let length = chartData.datasets[0].data.length;
            var nextMonthIndex = months.indexOf(labels[labels.length - 1]) + 1;
            var nextMonthName = length;
            counter = counter + 1;

            labels.push(counter);
            // setTimeout(() => {
            labels.shift();
            // }, 3000);
        }

        function setData(oldData, newData) {
            oldData.push(newData);
            // setTimeout(() => {
            oldData.shift();
            // }, 3000);
        }
        
        function convertMonthNameToNumber(monthName) {
            var myDate = new Date(monthName + " 1, 2016");
            var monthDigit = myDate.getMonth();
            return isNaN(monthDigit) ? 0 : (monthDigit + 1);
        }
        
        var months = [];

    // });
    var loaderElement = document.getElementById("loader");
    loaderElement.classList.remove("is-hide");
    
    let model = null;
    let testData = []

    async function loadModel() {
            try {
                var socket = io("http://localhost:3000/");
                let totalDelay = 500;
                socket.on('rawdata', function(data) {
                    totalDelay = totalDelay + 500;
                    setTimeout(() => {
                        if (counter >= 128){
                            counter = 0;
                        }
                        
                        setData(chartData.datasets[0].data, data);
                        // setLabels(chartData.labels);
                        let myLineChart = new Chart(ctx).Line(chartData, options);
                    }, totalDelay);
                        
                });
                socket.on('connection', (socket) => {
                    console.log('a user connected');
                });
            } catch (error) {
                console.log(error)
            }
            

            model = await tf.loadLayersModel("http://localhost/video/model.json");
            console.log("model loaded")
            let utils = new Utils('errorMessage');
            let streaming = false;
            utils.loadOpenCv(() => {
                let eyeCascadeFile = 'haarcascade_eye.xml';
                utils.createFileFromUrl(eyeCascadeFile, "https://grafias-dev.s3.eu-central-1.amazonaws.com/js/haarcascade_eye.xml", () => {
                    let faceCascadeFile = 'haarcascade_frontalface_default.xml';
                    utils.createFileFromUrl(faceCascadeFile, "https://grafias-dev.s3.eu-central-1.amazonaws.com/js/haarcascade_frontalface_default.xml", () => {
                        loaderElement.classList.add("is-hide");
                        var mainContentElement = document.getElementById("mainContent");
                        mainContentElement.classList.remove("is-hide");
                    });
                })
            
                
                let videoInput = document.getElementById('videoInput');
                let startAndStop = document.getElementById('startAndStop');
                let canvasOutput = document.getElementById('canvasOutput');
                let canvasContext = canvasOutput.getContext('2d');
                
                startAndStop.addEventListener('click', () => {
                    if (!streaming) {
                        utils.startCamera('qvga', onVideoStarted, 'videoInput');
                    } else {
                        utils.stopCamera();
                        onVideoStopped();
                    }
                });
                const FPS = 30;
                const indexOfMax = (arr) => {
                    if (arr.length === 0) {
                        return -1;
                    }

                    var max = arr[0];
                    var maxIndex = 0;

                    for (var i = 1; i < arr.length; i++) {
                        if (arr[i] > max) {
                            maxIndex = i;
                            max = arr[i];
                        }
                    }

                    return maxIndex;
                }
                function processVideo() {
                    try {
                        let video = document.getElementById('videoInput');
                        let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
                        

                        let cap = new cv.VideoCapture(video);
                        if (!streaming) {
                            // clean and stop.
                            src.delete();
                            return;
                        }

                        let begin = Date.now();
                        // start processing.
                        cap.read(src);
                
                        let gray = new cv.Mat();
                        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
                        let faces = new cv.RectVector();
                        let eyes = new cv.RectVector();
                        let faceCascade = new cv.CascadeClassifier();
                        let eyeCascade = new cv.CascadeClassifier();
                        // load pre-trained classifiers
                        faceCascade.load('haarcascade_frontalface_default.xml');
                        eyeCascade.load('haarcascade_eye.xml');
                        // detect faces
                        // detect faces
                        let msize = new cv.Size(0, 0);
                        faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize, msize);
                        if (faces.size() <= 0) analizingOutput.textContent = "No Face Detected"
                        for (let i = 0; i < faces.size(); ++i) {
                            analizingOutput.textContent = "Analizing " + Math.floor((testData.length/900)* 100)  + "%"
                            let roiGray = gray.roi(faces.get(i));
                            let roiSrc = src.roi(faces.get(i));
                            let point1 = new cv.Point(faces.get(i).x, faces.get(i).y);
                            let point2 = new cv.Point(faces.get(i).x + faces.get(i).width,
                                                    faces.get(i).y + faces.get(i).height);
                            cv.rectangle(src, point1, point2, [255, 0, 0, 255]);
                            testData.push(faces.get(i).x - 0, faces.get(i).y - 0)
                            console.log("iterasi ke:", testData.length)
                            if (testData.length === 900) {
                                analizingOutput.textContent = "Processing..."
                                const output = model.predict(tf.tensor([[testData]]));
                                const outputData = output.dataSync();
                                const index = indexOfMax(outputData)
                                if (index === 0) {
                                    classOutput.textContent = 'Central Sleep Apnea'
                                }
                                
                                if (index === 1) {
                                    classOutput.textContent = 'No Apnea'
                                } 

                                if (index === 2) {
                                    classOutput.textContent = 'Obstructive Sleep Apnea'
                                }

                                console.log(outputData)
                                testData.splice(0, 300);
                            }

                            roiGray.delete(); roiSrc.delete();
                        }
                        cv.imshow('canvasOutput', src);
                        src.delete(); 
                        gray.delete(); 
                        faceCascade.delete();
                        eyeCascade.delete(); 
                        faces.delete(); 
                        eyes.delete();

                        // schedule the next one.
                        let delay = 1000/FPS - (Date.now() - begin);
                        console.log(delay)
                        setTimeout(processVideo, 0);
                    } catch (err) {
                        utils.printError(err);
                    }
                };

                // main method
                function onVideoStarted() {
                    streaming = true;
                    startAndStop.innerText = 'Stop';
                    videoInput.width = videoInput.videoWidth;
                    videoInput.height = videoInput.videoHeight;
                    testData = []
                    // schedule the first one.
                    setTimeout(processVideo, 0);
                    
                
                }
                
                function onVideoStopped() {
                    startAndStop.innerText = 'Start';
                    streaming = false;
                    canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
                    classOutput.textContent = ""
                    analizingOutput.textContent = ""
                }
                
        });
    }
    loadModel();
    

</script>


</body>
</html>