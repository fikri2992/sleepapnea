<!DOCTYPE HTML>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script src="https://cdn.tailwindcss.com"></script>
<title>Analisa tidur Ver. 0.0.2</title>
<link href="./Video Capture Example_files/js_example_style.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"> </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/1.0.2/Chart.min.js"></script>
<style>
    .center {
        margin: auto;
        width: 60%;
        padding: 10px;
    }
    .loader {
        border: 16px solid #f3f3f3; /* Light grey */
        border-top: 16px solid #3498db; /* Blue */
        border-radius: 50%;
        width: 120px;
        height: 120px;
        animation: spin 2s linear infinite;
    }

    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    .is-hide{
        display: none;
    }
    #myChart {
        width:1920px !important;
        height:400px !important;
    }
</style>
</head>

<body>
    <div id="loader" class="is-hide mt-[25%] ml-[50%]" >
        <div class="loader"></div>
        <div>Loading Model</div>
    </div>
    <div id="mainContent" class="is-hide">
        <p class="err" id="errorMessage"></p>
        <div>
            <table cellpadding="0" cellspacing="0" width="0" border="0">
                <tbody>
                    <tr>
                        <td>
                            <video id="videoInput" style="display:none" width="320" height="240"></video>
                        </td>
                        <td>
                            <canvas id="canvasOutput" width="320" height="240"></canvas>
                        </td>
                        <td></td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>
                            <div class="caption" style="display:none">videoInput</div>
                        </td>
                        <td>
                            <!-- <div class="center"> -->
                                <div class="control"><button id="startAndStop">Start</button></div>
                                <textarea style="display:none" class="code" rows="29" cols="100" id="codeEditor" spellcheck="false"></textarea>
                            <!-- </div> -->
                            <div id="output" class="caption"></div>
                            <div id="analizing" class="caption"></div>
                        </td>
                        <td></td>
                        <td></td>
                    </tr>
                </tbody>
            </table>
        </div>
        <div>
            <canvas id="myChart" width="1920" height="400" style="width: 1920px !important;; height: 400px !important;"></canvas>
        </div>
    </div>

<!-- <script async src="https://grafias-dev.s3.eu-central-1.amazonaws.com/js/opencv.js" type="text/javascript"></script> -->
<script src="./Video Capture Example_files/adapter-5.0.4.js" type="text/javascript"></script>
<script src="./Video Capture Example_files/utils.js" type="text/javascript"></script>


<script type="text/javascript">
    $(document).ready(function() {
        var ctx = document.getElementById("myChart").getContext("2d");
        ctx.canvas.parentNode.style.height = '400px';
        ctx.canvas.parentNode.style.width = '1920px';
        const defaultData = Array.from(Array(128).keys())

        var data = {
            labels: defaultData,
            width:1920,
            height:400,
            datasets: [{
                label: "My First dataset",
                fillColor: "rgba(220,220,220,0.2)",
                strokeColor: "rgba(220,220,220,1)",
                pointColor: "rgba(220,220,220,1)",
                pointStrokeColor: "#fff",
                pointHighlightFill: "#fff",
                pointHighlightStroke: "rgba(220,220,220,1)",
                data: Array.from({length: 128}, () => Math.floor(Math.random() * 100))
            }]
        };
        var options = {
            animation: false,
            width: 1920,
            height: 400,
            //Boolean - If we want to override with a hard coded scale
            scaleOverride: true,
            //** Required if scaleOverride is true **
            //Number - The number of steps in a hard coded scale
            scaleSteps: 10,
            //Number - The value jump in the hard coded scale
            scaleStepWidth: 10,
            //Number - The scale starting value
            scaleStartValue: 0,
            responsive: false,
        };

        var myLineChart = new Chart(ctx).Line(data, options);
        let counter = data.datasets[0].data.length;
        
        setInterval(function() {
            if (counter >= 128){
                counter = 0;
            }

            setData(data.datasets[0].data);
            setLabels(data.labels);
            var myLineChart = new Chart(ctx).Line(data, options);
        }, 1000);

        function setLabels(labels) {
            let length = data.datasets[0].data.length;
            var nextMonthIndex = months.indexOf(labels[labels.length - 1]) + 1;
            var nextMonthName = length;
            counter = counter + 1;

            labels.push(counter);
            // setTimeout(() => {
            labels.shift();
            // }, 3000);
        }

        function setData(data) {
            data.push(Math.floor(Math.random() * 100) + 1);
            // setTimeout(() => {
            data.shift();
            // }, 3000);
        }
        
        function convertMonthNameToNumber(monthName) {
            var myDate = new Date(monthName + " 1, 2016");
            var monthDigit = myDate.getMonth();
            return isNaN(monthDigit) ? 0 : (monthDigit + 1);
        }
        
        var months = [];

    });
    var loaderElement = document.getElementById("loader");
    loaderElement.classList.remove("is-hide");
    
    let model = null;
    let testData = []
    async function loadModel() {
            model = await tf.loadLayersModel("http://localhost/video/model.json");
            tf.tensor([1, 2, 3, 4]).print()
            console.log("model loaded")
            let utils = new Utils('errorMessage');
            let streaming = false;
            utils.loadOpenCv(() => {
                let eyeCascadeFile = 'haarcascade_eye.xml';
                utils.createFileFromUrl(eyeCascadeFile, "https://grafias-dev.s3.eu-central-1.amazonaws.com/js/haarcascade_eye.xml", () => {
                    let faceCascadeFile = 'haarcascade_frontalface_default.xml';
                    utils.createFileFromUrl(faceCascadeFile, "https://grafias-dev.s3.eu-central-1.amazonaws.com/js/haarcascade_frontalface_default.xml", () => {
                        loaderElement.classList.add("is-hide");
                        var mainContentElement = document.getElementById("mainContent");
                        mainContentElement.classList.remove("is-hide");
                    });
                })
            
                
                let videoInput = document.getElementById('videoInput');
                let startAndStop = document.getElementById('startAndStop');
                let canvasOutput = document.getElementById('canvasOutput');
                let canvasContext = canvasOutput.getContext('2d');
                
                startAndStop.addEventListener('click', () => {
                    if (!streaming) {
                        utils.clearError();
                        utils.startCamera('qvga', onVideoStarted, 'videoInput');
                    } else {
                        utils.stopCamera();
                        onVideoStopped();
                    }
                });
                const FPS = 30;
                const indexOfMax = (arr) => {
                    if (arr.length === 0) {
                        return -1;
                    }

                    var max = arr[0];
                    var maxIndex = 0;

                    for (var i = 1; i < arr.length; i++) {
                        if (arr[i] > max) {
                            maxIndex = i;
                            max = arr[i];
                        }
                    }

                    return maxIndex;
                }
                function processVideo() {
                    try {
                        let video = document.getElementById('videoInput');
                        let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
                        let classOutput = document.getElementById('output')
                        let analizingOutput = document.getElementById('analizing')

                        let cap = new cv.VideoCapture(video);
                        if (!streaming) {
                            // clean and stop.
                            src.delete();
                            return;
                        }

                        let begin = Date.now();
                        // start processing.
                        cap.read(src);
                
                        let gray = new cv.Mat();
                        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
                        let faces = new cv.RectVector();
                        let eyes = new cv.RectVector();
                        let faceCascade = new cv.CascadeClassifier();
                        let eyeCascade = new cv.CascadeClassifier();
                        // load pre-trained classifiers
                        faceCascade.load('haarcascade_frontalface_default.xml');
                        eyeCascade.load('haarcascade_eye.xml');
                        // detect faces
                        // detect faces
                        let msize = new cv.Size(0, 0);
                        faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize, msize);
                        if (faces.size() <= 0) analizingOutput.textContent = "No Face Detected"
                        for (let i = 0; i < faces.size(); ++i) {
                            analizingOutput.textContent = "Analizing"
                            let roiGray = gray.roi(faces.get(i));
                            let roiSrc = src.roi(faces.get(i));
                            let point1 = new cv.Point(faces.get(i).x, faces.get(i).y);
                            let point2 = new cv.Point(faces.get(i).x + faces.get(i).width,
                                                    faces.get(i).y + faces.get(i).height);
                            cv.rectangle(src, point1, point2, [255, 0, 0, 255]);
                            testData.push(faces.get(i).x - 0, faces.get(i).y - 0)
                            console.log("iterasi ke:", testData.length)
                            if (testData.length === 900) {
                                analizingOutput.textContent = "Processing..."
                                const output = model.predict(tf.tensor([[testData]]));
                                const outputData = output.dataSync();
                                const index = indexOfMax(outputData)
                                if (index === 0) {
                                    classOutput.textContent = 'Central Sleep Apnea'
                                }
                                
                                if (index === 1) {
                                    classOutput.textContent = 'No Apnea'
                                } 

                                if (index === 2) {
                                    classOutput.textContent = 'Obstructive Sleep Apnea'
                                }

                                console.log(outputData)
                                testData = []
                            }

                            roiGray.delete(); roiSrc.delete();
                        }
                        cv.imshow('canvasOutput', src);
                        src.delete(); 
                        gray.delete(); 
                        faceCascade.delete();
                        eyeCascade.delete(); 
                        faces.delete(); 
                        eyes.delete();

                        // schedule the next one.
                        let delay = 1000/FPS - (Date.now() - begin);
                        console.log(delay)
                        setTimeout(processVideo, delay);
                    } catch (err) {
                        utils.printError(err);
                    }
                };

                // main method
                function onVideoStarted() {
                    streaming = true;
                    startAndStop.innerText = 'Stop';
                    videoInput.width = videoInput.videoWidth;
                    videoInput.height = videoInput.videoHeight;
                    // schedule the first one.
                    setTimeout(processVideo, 0);
                    
                
                }
                
                function onVideoStopped() {
                    streaming = false;
                    canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
                    startAndStop.innerText = 'Start';
                }
                
        });
    }
    loadModel();
    

</script>


</body>
</html>